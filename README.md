# PoseDetector_and_AI-ActivityTracker

This is a 2 session project. First session includes https://teachablemachine.withgoogle.com pose model training and testing. During the session you will be able to train from your own images and identify the "labeled movements" from your own camera. Second session includes https://createai.microbit.org to create a Machine Learning model to identify the microbit's accelerometer data patterns.

Requirements:
* 1x micro:bit
* 1x micro:bit holder
* 1x microb:bit holder strap
* 1x Battery 
* 1x USB-C Cable
* Access to a computer with internet access and a running camera

<img src="https://github.com/user-attachments/assets/1371b121-5d56-4ecb-84be-4e04e0f1648a" alt="List" width="500" height="400">


First session only requires a computer with webcam and the project will run on https://teachablemachine.withgoogle.com for both training and testing. Example project should look like the below image.

<img src="https://github.com/user-attachments/assets/8b2a212e-1f0a-409f-8099-b97753a0327a" alt="List" width="700" height="500">

Second session requires the microbit, battery, USB-C cable and a computer with internet access. It will run on https://createai.microbit.org and it is able to estimate users activity(staying still, walking and exercising).

<img src="https://github.com/user-attachments/assets/45075326-51cd-4079-b8df-d0e61c4080a8" alt="List" width="700" height="500">

How to do the activities:
* For the first session: Go to [1-)PoseDetector/Instructions.txt]https://github.com/WestHoustonInstitute/PoseDetector_and_AI-ActivityTracker/blob/main/1-)PoseDetector/Instructions.txt and follow the instructions.
* For the second session: Go to [2-)AI-ActivityTracker/Instructions.txt]https://github.com/WestHoustonInstitute/PoseDetector_and_AI-ActivityTracker/blob/main/2-)AI-ActivityTracker/Instructions.txt and follow the instructions.
